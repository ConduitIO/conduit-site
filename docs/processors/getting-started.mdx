---
title: 'Getting Started with Processors'
sidebar_label: "Getting Started"
sidebar_position: 0
---

A processor is a component that operates on a single record that flows through a pipeline. It can either **transform** the record, or **filter** it out based on some criteria. Since they are part of pipelines, making 
yourself familiar with [pipeline semantics](/docs/features/pipeline-semantics) is highly recommended.

![Pipeline](/img/pipeline_example.svg)

Processors are **optional** components in a pipeline (i.e. a pipeline can be started without them), and they are always
attached to a single parent, which can be either a connector or a pipeline:

- **Connector processors**:
  - **Source processors** only receive messages originating at a specific source connector. Source
   processors are created by specifying the corresponding source connector as the parent entity.
   - **Destination processors** only receive messages that are meant to be sent to a specific
   destination connector. Destination processors are created by specifying the corresponding destination connector as
   the parent entity.
- **Pipeline processors** receive all messages that flow through the pipeline, regardless of the
   source or destination. Pipeline processors are created by specifying the pipeline as the parent entity.


## Supported processors

Whenit comes to using a processor either on a connector, or a pipeline, Conduit supports different types:

- [Built-in processors](/docs/processors/builtin) will perform the most common operations you could expect such as filtering fields, replacing fields, posting payloads to a HTTP endpoint, etc. These are already coming as part of Conduit, and you can simply start using them with a bit of configuration. [Check out this document to see everything that's available](/docs/processors/builtin).
- [Standalone processors](/docs/processors/standalone-processors) are the ones you could write yourself to do anything that's not already covered by the [Built-in](/docs/processors/builtin) ones. [Here's](/docs/processors/standalone-processors) more information about them.

## How to use a processor for your pipeline or connector

In these following examples, we're using the [`json.decode`](/docs/processors/builtin/json.decode), but you could use [any other you'd like](/docs/processors/builtin/).

:::note

When referencing the name of a processor there are different ways you can make sure you're using the one you'd like. Please, check out the [Referencing Processors](/docs/processors/referencing) documentation for more information.

:::


### Through a pipeline configuration file

#### Using a pipeline processor

Creating a pipeline processor through a pipeline configuration file can be done as below:

```yaml
version: 2.2
pipelines:
  - id: example-pipeline
    connectors:
    # define source and destination connectors
    # ...
    processors:
      - id: extract-name
        plugin: json.decode
        settings:
          field: name
```

#### Using a connector processor

Similarly, we can configure a connector processor, i.e. a processor attached to a connector:

```yaml
version: 2.2
pipelines:
  - id: example-pipeline
    connectors:
      - id: conn1
        # other connector configuration
        processors:
          - id: extract-name
            plugin: json.decode
            settings:
              field: name
      # other connectors
```

The documentation about pipeline configuration files can be found [here](/docs/configuration/pipeline-configuration-files).

### Through the HTTP API

The processor endpoints live under the `/v1/processors` namespace, and if you'd like to use our [HTTP API](/api) t attach a processor to either connector or a pipeline, here's how you could do it.

#### Using a pipeline processor

```json lines
POST /v1/processor
{
  "parent": {
    "type": "TYPE_PIPELINE",
    "id": "pipeline-id"
  },
  "config": {
    "settings": {
      "field": "name"
    },
    "workers": 0
  },
  "condition": "string",
  "plugin": "json.decode"
}
```

#### Using a connector processor

```json lines
POST /v1/processor
{
  "parent": {
    "type": "TYPE_CONNECTOR",
    "id": "connector-id"
  },
  "config": {
    "settings": {
      "field": "name"
    },
    "workers": 0
  },
  "condition": "string",
  "plugin": "json.decode"
}
```

#### Check the processor was successfully created

To list all processors that are registered in your pipeline (either connector or pipeline processors) you can make the following request:

```json lines
GET /v1/processors
[
  {
    "condition": "string",
    "config": {
      "settings": {},
      "workers": 0
    },
    "createdAt": "1970-01-01T00:00:00.000Z",
    "id": "string",
    "parent": {
      "id": "string",
      "type": "TYPE_UNSPECIFIED"
    },
    "plugin": "json.decode",
    "updatedAt": "1970-01-01T00:00:00.000Z"
  }
]
```

:::tip

To list all the different API HTTP requests you could perform check out [our API](/api). These are also described in our [api.swagger.json](https://github.com/ConduitIO/conduit/blob/main/pkg/web/openapi/swagger-ui/api/v1/api.swagger.json).

:::


