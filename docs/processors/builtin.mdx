---
title: 'Built-in processors'
sidebar_position: 1
---

:::note
Note that all built-in processors that operate on the payload actually operate on `Record.Payload.After`.
If you need to manipulate the field `Record.Payload.Before` you can use
a [JavaScript processor](./javascript-processors).
:::

Below is a list of available built-in processors in Conduit. An example usage of a built-in processor is available in
[`extract-field-transform.sh`](https:github.com/ConduitIO/conduit/blob/main/examples/processors/extract-field-transform.sh).
The script will run Conduit with a pipeline containing the built-in `extractfieldpayload` processor.

### extractfieldkey

Extracts a field from the key and uses it to replace the entire key. If the key is raw, returns an error (not
supported).

#### Configuration

- `field` (Required)

  Name of the field which replaces the entire key.

### extractfieldpayload

Works in the same way as [extractfieldkey](#extractfieldkey), except that it's applied to `Record.Payload.After`.

### filterfieldkey

In `filterfieldkey`, the key is viewed as a JSON document and matched against an XPath expression.

#### Configuration

- `type` (Required)

  Sets the behavior to "include" or "exclude" the record based on the result of the condition. Possible values
  are: `include`, `exclude`.

- `condition` (Required, XPath expression)

  An XPath query expression that the user defines to forward or drop a record on its results.

- `missingornull` (Optional)

  Defines how to handle the record in the event the fields the query would use don't exist. Possible values
  are: `fail`, `include`, `exclude`. Defaults to `fail`.

- `exists` (Optional)

  An XPath query expression used as an existence query for the node(s) used in `condition`.

If `condition` matches, then it will handle the record as `type` dictates (i.e. keep the record, drop it, or return an
error).

If `condition` **doesn't** match anything, then we can use the `exists` expression to check if the JSON nodes used
in `condition` actually exist. If `exists` doesn't match any node, then the record is handled as `missingornull`
specifies. If `exists` is not configured or matches a node, then the record is dropped.

### filterfieldpayload

Works in the same way as [filterfieldkey](#filterfieldkey), except that it's applied to `Record.Payload.After`.

### hoistfieldkey

`hoistfieldkey` works in the following way:

- If the key is raw, transforms it into structured data by creating a map with the hoisted field and
  raw data as the value.
- If the key is structured, wraps it using the specified field name in a map.

#### Configuration

- `field` (Required)

  Name of the field which replaces the entire key.

### hoistfieldpayload

`hoistfieldpayload` builds the same processor as [hoistfieldkey](#hoistfieldkey), except that it operates on the field
`Record.Payload.After`.

### httprequest

`httprequest` replaces a record's `Payload.After` field with the response of the HTTP request. The response body is
wrapped in `RawData`.

#### Configuration

- `url` (Required)

  URL used in the HTTP request.
- `method` (Optional)

  HTTP request method to be used. Defaults to `POST`.
- `backoffRetry.count` (Optional, integer)

  Maximum number of retries when backing off following an error. Defaults to 0.
- `backoffRetry.factor` (Optional, integer)

  The multiplying factor for each increment step. Defaults to 2.
- `backoffRetry.min` (Optional, [duration string](https://pkg.go.dev/time#ParseDuration))

  Minimum waiting time before retrying. Defaults to `100ms`.
- `backoffRetry.max` (Optional, [duration string](https://pkg.go.dev/time#ParseDuration))
  
  Maximum waiting time before retrying. Defaults to `5s`.

### insertfieldkey

Inserts a field into a record's key. It's possible to insert a static value or the record's position. If the field
already
exists, it's overwitten. Raw keys are not supported yet.

#### Configuration

- `static.field` (Required, if `position.field` is not set)

  Name of the field into which the value in `static.value` will be inserted.
- `static.value` (Required, if `static.field` is set)

  Value to be inserted.
- `position.field` (Required, if `static.field` is not set)

  Name of the field into which the record's position will be inserted.

### insertfieldpayload

Works in the same way as [insertfieldkey](#insertfieldkey), except that it's applied to `Record.Payload.After`.

### maskfieldkey

`maskfieldkey` replaces a field in a key with structured data with the zero value of its type. If the field is a string,
an interger, or a float it's possible to define a replacement value. Raw keys are not supported yet.

#### Configuration

- `field` (Required)

  Name of the field to be masked.

- `replacement` (Optional)

  Replacement value. Defaults to the field type's zero value (e.g. empty string for strings, 0 for integers etc.)

### maskfieldpayload

Works in the same way as [maskfieldpayload](#maskfieldpayload), except that it's applied to `Record.Payload.After`.

### parsejsonkey

Transforms the record's key into structured data, i.e. a JSON object.

### parsejsonpayload

Transforms the record's `Payload.After` into structured data, i.e. a JSON object.

### replacefieldkey

Replaces a field in a record's key. Keys with raw data are not supported yet.

#### Configuration

At least one of the following parameters is required.

- `exclude`

A comma separated list of fields that should be excluded from the processed record (`exclude` takes precedence
over `include`).

- `include`

  A comma separated list of fields that should be included in the processed record.
- `rename`

  A comma separated list of pairs separated by colons, that controls the mapping of old field names to new field names.

If `include` is not configured or is empty then all fields in the record will be included by default (except if they are
configured in `exclude`). If `include` is not empty, then all fields are excluded by default and only fields
in `include` will be added to the processed record.

### replacefieldpayload

Works in the same way as [replacefieldkey](#replacefieldkey), except that it's applied to `Record.Payload.After`.

### timestampconvertorkey

Converts a timestamp in a field in the key into a different type. The supported types are:

- `string`
- `unix`
- `time.Time`

Any combination of the supported types is possible. For example, it's possible to convert from a Unix timestamp to Go's
`time.Time` or to convert from a string to a Unix timestamp.

The processor supports only structured data.

#### Configuration

- `date` (Required, string)

  Name of field which contains timestamp data.
- `target.type` (Required)

  The target type into which the field's value will be converted. Possible values are `string`, `unix`, `time.Time`.
- `format` (Required if the input value is a string or the target type is `string`)

  Timestamp format to be used to parse the input value (found in the `date` field) or to format the output value.

### timestampconvertorpayload

Works in the same way as [timestampconvertorkey](#timestampconvertorkey), except that it's applied
to `Record.Payload.After`.

### unwrap

Unwraps a Debezium or a Kafka Connect record from the input OpenCDC record. This is useful in cases where Conduit acts
as an intermediary between a Debezium/Kafka Connect source and a Debezium/Kafka Connect destination. In such cases, the
Debezium or Kafka Connect record is set as the OpenCDC record's payload, and needs to be unwrapped for further usage.

#### Configuration

- `format` (Required)

  Format of the payload to be unwrapped. Possible values are: `debezium`, `kafka-connect`. In case of `debezium`, the
  processor will fail if the input payload isn't a valid Debezium record.

### valuetokey

`valuetokey` builds a processor that replaces the record key with a new key formed from a subset of fields in
`Record.Payload.After`. If `Record.Payload.After` is raw the processor returns an error.
