---
title: 'Built-in processors'
sidebar_position: 1
---

:::note
Note that all built-in processors that operate on the payload actually operate on `Record.Payload.After`.
If you need to manipulate the field `Record.Payload.Before` you can use
a [JavaScript processor](./javascript-processors).
:::

Below is a list of available built-in processors in Conduit. An example usage of a built-in processor is available in
[`pipeline-extract-field-transform.yml`](https://github.com/ConduitIO/conduit/blob/main/examples/processors/pipeline-extract-field-transform.yml).
The script will run Conduit with a pipeline containing the built-in `extractfieldpayload` processor.

### decodewithschemakey

The processor takes raw data (bytes) in field `Record.Key` and decodes it from the
[Confluent wire format](https://docs.confluent.io/platform/current/schema-registry/fundamentals/serdes-develop/index.html#wire-format)
into structured data. It extracts the schema ID from the data, downloads the
associated schema from the
[schema registry](https://docs.confluent.io/platform/current/schema-registry/index.html)
and decodes the payload. The schema is cached locally after it's first
downloaded. Currently, the processor only supports the Avro format. If the
processor encounters structured data or the data can't be decoded it returns an
error.

This processor is the counterpart to [`encodewithschemakey`](#encodewithschemakey).

#### Configuration

- `url` (Required)

  URL of the schema registry (e.g. `http://localhost:8085`)

- `auth.basic.username` (Optional)

  Configures the username to use with basic authentication. This option is required if `auth.basic.password` contains a value.
  If both `auth.basic.username` and `auth.basic.password` are empty basic authentication is disabled.

- `auth.basic.password` (Optional)

  Configures the password to use with basic authentication. This option is required if `auth.basic.username` contains a value.
  If both `auth.basic.username` and `auth.basic.password` are empty basic authentication is disabled.

- `tls.ca.cert` (Optional)

  Path to a file containing PEM encoded CA certificates. If this option is empty, Conduit falls back to using the host's root CA set.

- `tls.client.cert` (Optional)

  Path to a file containing a PEM encoded certificate. This option is required if `tls.client.key` contains a value.
  If both `tls.client.cert` and `tls.client.key` are empty TLS is disabled.

- `tls.client.key` (Optional)

  Path to a file containing a PEM encoded private key. This option is required if `tls.client.cert` contains a value.
  If both `tls.client.cert` and `tls.client.key` are empty TLS is disabled.

#### Example

```yaml
processors:
  id:   example
  type: decodewithschemakey
  settings:
    url:                 "http://localhost:8085"
    auth.basic.username: "user"
    auth.basic.password: "pass"
    tls.ca.cert:         "/path/to/ca/cert"
    tls.client.cert:     "/path/to/client/cert"
    tls.client.key:      "/path/to/client/key"
```

### decodewithschemapayload

Works in the same way as [decodewithschemakey](#decodewithschemakey), except that it's applied to `Record.Payload.After`.

This processor is the counterpart to [`encodewithschemapayload`](#encodewithschemapayload).

### encodewithschemakey

The processor takes structured data and encodes it using a schema into the
[Confluent wire format](https://docs.confluent.io/platform/current/schema-registry/fundamentals/serdes-develop/index.html#wire-format).
It provides two strategies for determining the schema:

- `preRegistered` (recommended)

  This strategy downloads an existing schema from the
  [schema registry](https://docs.confluent.io/platform/current/schema-registry/index.html)
  and uses it to encode the record. This requires the schema to already be
  registered in the schema registry. The schema is downloaded only once and
  cached locally.

- `autoRegister` (for development purposes)

  This strategy infers the schema by inspecting the structured data and
  registers it in the
  [schema registry](https://docs.confluent.io/platform/current/schema-registry/index.html).
  If the record schema is known in advance it's recommended to use the
  `preRegistered` strategy and manually register the schema, as this strategy comes
  with limitations.

  The strategy uses reflection to traverse the structured data of each record
  and determine the type of each field. If a specific field is set to `nil` the
  processor won't have enough information to determine the type and will default
  to a nullable string. Because of this it is not guaranteed that two records
  with the same structure produce the same schema or even a backwards compatible
  schema. The processor registers each inferred schema in the schema registry
  with the same subject, therefore the schema compatibility checks need to be
  disabled for this schema to prevent failures. If the schema subject does not
  exist before running this processor, it will automatically set the correct
  compatibility settings in the schema registry.

The processor currently only supports the Avro format.

This processor is the counterpart to [`decodewithschemakey`](#decodewithschemakey).

#### Configuration

- `url` (Required)

  URL of the schema registry (e.g. `http://localhost:8085`)

- `schema.strategy` (Required, Enum: `preRegistered`,`autoRegister`)

  Specifies which strategy to use to determine the schema for the record.
  Available strategies:

    - `preRegistered` (recommended) - Download an existing schema from the schema
      registry. This strategy is further configured with options starting with
      `schema.preRegistered.*`.

    - `autoRegister` (for development purposes) - Infer the schema from the
      record and register it in the schema registry. This strategy is further
      configured with options starting with `schema.autoRegister.*`.

  For more information about the behavior of each strategy read the main
  processor description.

- `schema.preRegistered.subject` (Required if `schema.strategy` = `preRegistered`)

  Specifies the subject of the schema in the schema registry used to encode the
  record.

- `schema.preRegistered.version` (Required if `schema.strategy` = `preRegistered`)

  Specifies the version of the schema in the schema registry used to encode the
  record.

- `schema.autoRegister.subject` (Required if `schema.strategy` = `autoRegister`)

  Specifies the subject name under which the inferred schema will be registered
  in the schema registry.

- `schema.autoRegister.format` (Required if `schema.strategy` = `autoRegister`, Enum: `avro`)

  Specifies the schema format that should be inferred. Currently the only
  supported format is `avro`.

- `auth.basic.username` (Optional)

  Configures the username to use with basic authentication. This option is required if `auth.basic.password` contains a value.
  If both `auth.basic.username` and `auth.basic.password` are empty basic authentication is disabled.

- `auth.basic.password` (Optional)

  Configures the password to use with basic authentication. This option is required if `auth.basic.username` contains a value.
  If both `auth.basic.username` and `auth.basic.password` are empty basic authentication is disabled.

- `tls.ca.cert` (Optional)

  Path to a file containing PEM encoded CA certificates. If this option is empty, Conduit falls back to using the host's root CA set.

- `tls.client.cert` (Optional)

  Path to a file containing a PEM encoded certificate. This option is required if `tls.client.key` contains a value.
  If both `tls.client.cert` and `tls.client.key` are empty TLS is disabled.

- `tls.client.key` (Optional)

  Path to a file containing a PEM encoded private key. This option is required if `tls.client.cert` contains a value.
  If both `tls.client.cert` and `tls.client.key` are empty TLS is disabled.

#### Example

```yaml
processors:
  id:   example
  type: encodewithschemakey
  settings:
    url:                          "http://localhost:8085"
    schema.strategy:              "preRegistered"
    schema.preRegistered.subject: "foo"
    schema.preRegistered.version: 2
    auth.basic.username:          "user"
    auth.basic.password:          "pass"
    tls.ca.cert:                  "/path/to/ca/cert"
    tls.client.cert:              "/path/to/client/cert"
    tls.client.key:               "/path/to/client/key"
```

### encodewithschemapayload

Works in the same way as [encodewithschemakey](#encodewithschemakey), except that it's applied to `Record.Payload.After`.

This processor is the counterpart to [`decodewithschemapayload`](#decodewithschemapayload).

### extractfieldkey

Extracts a field from the key and uses it to replace the entire key. If the key is raw, returns an error (not
supported).

#### Configuration

- `field` (Required)

  Name of the field which replaces the entire key.

### extractfieldpayload

Works in the same way as [extractfieldkey](#extractfieldkey), except that it's applied to `Record.Payload.After`.

### filterfieldkey

In `filterfieldkey`, the key is viewed as a JSON document and matched against an XPath expression.

#### Configuration

- `type` (Required)

  Sets the behavior to "include" or "exclude" the record based on the result of the condition. Possible values
  are: `include`, `exclude`.

- `condition` (Required, XPath expression)

  An XPath query expression that the user defines to forward or drop a record on its results.

- `missingornull` (Optional)

  Defines how to handle the record in the event the fields the query would use don't exist. Possible values
  are: `fail`, `include`, `exclude`. Defaults to `fail`.

- `exists` (Optional)

  An XPath query expression used as an existence query for the node(s) used in `condition`.

If `condition` matches, then it will handle the record as `type` dictates (i.e. keep the record, drop it, or return an
error).

If `condition` **doesn't** match anything, then we can use the `exists` expression to check if the JSON nodes used
in `condition` actually exist. If `exists` doesn't match any node, then the record is handled as `missingornull`
specifies. If `exists` is not configured or matches a node, then the record is dropped.

### filterfieldpayload

Works in the same way as [filterfieldkey](#filterfieldkey), except that it's applied to `Record.Payload.After`.

### hoistfieldkey

`hoistfieldkey` works in the following way:

- If the key is raw, transforms it into structured data by creating a map with the hoisted field and
  raw data as the value.
- If the key is structured, wraps it using the specified field name in a map.

#### Configuration

- `field` (Required)

  Name of the field which replaces the entire key.

### hoistfieldpayload

`hoistfieldpayload` builds the same processor as [hoistfieldkey](#hoistfieldkey), except that it operates on the field
`Record.Payload.After`.

### httprequest

`httprequest` replaces a record's `Payload.After` field with the response of the HTTP request. The response body is
wrapped in `RawData`.

#### Configuration

- `url` (Required)

  URL used in the HTTP request.
- `method` (Optional)

  HTTP request method to be used. Defaults to `POST`.
- `backoffRetry.count` (Optional, integer)

  Maximum number of retries when backing off following an error. Defaults to 0.
- `backoffRetry.factor` (Optional, integer)

  The multiplying factor for each increment step. Defaults to 2.
- `backoffRetry.min` (Optional, [duration string](https://pkg.go.dev/time#ParseDuration))

  Minimum waiting time before retrying. Defaults to `100ms`.
- `backoffRetry.max` (Optional, [duration string](https://pkg.go.dev/time#ParseDuration))
  
  Maximum waiting time before retrying. Defaults to `5s`.

### insertfieldkey

Inserts a field into a record's key. It's possible to insert a static value or the record's position. If the field
already
exists, it's overwitten. Raw keys are not supported yet.

#### Configuration

- `static.field` (Required, if `position.field` is not set)

  Name of the field into which the value in `static.value` will be inserted.
- `static.value` (Required, if `static.field` is set)

  Value to be inserted.
- `position.field` (Required, if `static.field` is not set)

  Name of the field into which the record's position will be inserted.

### insertfieldpayload

Works in the same way as [insertfieldkey](#insertfieldkey), except that it's applied to `Record.Payload.After`.

### maskfieldkey

`maskfieldkey` replaces a field in a key with structured data with the zero value of its type. If the field is a string,
an interger, or a float it's possible to define a replacement value. Raw keys are not supported yet.

#### Configuration

- `field` (Required)

  Name of the field to be masked.

- `replacement` (Optional)

  Replacement value. Defaults to the field type's zero value (e.g. empty string for strings, 0 for integers etc.)

### maskfieldpayload

Works in the same way as [maskfieldpayload](#maskfieldpayload), except that it's applied to `Record.Payload.After`.

### parsejsonkey

Transforms the record's raw data key (has to be JSON formatted) into structured data, i.e. a JSON object.

### parsejsonpayload

Transforms the record's raw `Payload.After` (has to be JSON formatted) into structured data, i.e. a JSON object.

### replacefieldkey

Replaces a field in a record's key. Keys with raw data are not supported yet.

#### Configuration

At least one of the following parameters is required.

- `exclude`

A comma separated list of fields that should be excluded from the processed record (`exclude` takes precedence
over `include`).

- `include`

  A comma separated list of fields that should be included in the processed record.
- `rename`

  A comma separated list of pairs separated by colons, that controls the mapping of old field names to new field names.

If `include` is not configured or is empty then all fields in the record will be included by default (except if they are
configured in `exclude`). If `include` is not empty, then all fields are excluded by default and only fields
in `include` will be added to the processed record.

### replacefieldpayload

Works in the same way as [replacefieldkey](#replacefieldkey), except that it's applied to `Record.Payload.After`.

### timestampconverterkey

Converts a timestamp in a field in the key into a different type. The supported types are:

- `string`
- `unix`
- `time.Time`

Any combination of the supported types is possible. For example, it's possible to convert from a Unix timestamp to Go's
`time.Time` or to convert from a string to a Unix timestamp.

The processor supports only structured data.

#### Configuration

- `date` (Required, string)

  Name of field which contains timestamp data.
- `target.type` (Required)

  The target type into which the field's value will be converted. Possible values are `string`, `unix`, `time.Time`.
- `format` (Required if the input value is a string or the target type is `string`)

  Timestamp format to be used to parse the input value (found in the `date` field) or to format the output value.

### timestampconverterpayload

Works in the same way as [timestampconverterkey](#timestampconverterkey), except that it's applied
to `Record.Payload.After`.

### unwrap

Unwraps a Debezium or a Kafka Connect record from the input OpenCDC record. This is useful in cases where Conduit acts
as an intermediary between a Debezium/Kafka Connect source and a Debezium/Kafka Connect destination. In such cases, the
Debezium or Kafka Connect record is set as the OpenCDC record's payload, and needs to be unwrapped for further usage.

#### Configuration

- `format` (Required)

  Format of the payload to be unwrapped. Possible values are: `debezium`, `kafka-connect`. In case of `debezium`, the
  processor will fail if the input payload isn't a valid Debezium record.

### valuetokey

`valuetokey` builds a processor that replaces the record key with a new key formed from a subset of fields in
`Record.Payload.After`. If `Record.Payload.After` is raw the processor returns an error.
