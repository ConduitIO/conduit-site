---
title: 'Schema Registry'
sidebar_position: 7
keywords: [ 'schema', 'avro', 'confluent' ]
---

The schema registry is used internally in Conduit store the schemas of records that are produced by connectors that generate **structured data** (encoded into [Avro format](https://avro.apache.org/)). The schema registry can either be embedded as part of Conduit (**built-in type**) or run as a standalone service exposing a REST API that's compatible with [Confluent's Schema registry](https://docs.confluent.io/current/schema-registry/develop/api.html) (**confluent type**).


To use an external schema registry, you can use the following configuration options in your [pipeline configuration file](/docs/pipeline-configuration-files/getting-started)

```yaml
schema-registry:
  type: confluent
  confluent:
    connection-string: http://localhost:8081
```

Or when running Conduit from the command line you can use the following flags:

```shell
$ ./conduit 
  -schema-registry.type=confluent 
  -schema-registry.confluent.connection-string=http://localhost:8081
```

When a record with structured data is processed, both schema subject and version are attached to the record metadata so it preserves all types when it comes to structured records. You can see an example on [`opencdc.payload.schema.*`](/docs/features/opencdc-record#opencdcpayloadschema).


When using a **built-in schema**, the schema registry service will use the same [**persistence layer**](/docs/getting-started/architecture#persistence-layer) as the rest of Conduit. By default, it uses BadgerDB, but it can be configured to use PostgreSQL, SQLite, or in-memory storage. More information on [storage](/docs/features/storage).

:::note
You can check the GitHub repository for the schema registry [here](https://github.com/conduitIO/conduit-schema-registry).
:::

