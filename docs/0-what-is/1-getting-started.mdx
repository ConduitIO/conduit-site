---
title: 'Getting Started'
sidebar_label: "Getting Started"
sidebar_position: 0
slug: '/getting-started'
---

## Our goal

In this guide, we'll learn how to install Conduit and use it to build and run a
pipeline. The pipeline will be continuously generating sample user data (using
the
built-in [generator connector](https://github.com/ConduitIO/conduit-connector-generator))
and printing the data to logs. The user data will contain an ID (which is an
integer) and a name (which is a string).

## Install Conduit

If you're using a macOS or Linux system, you can install Conduit with the
following command:

```shell
$ curl https://conduit.io/install.sh | bash
```

If you're not using macOS or Linux system, you can still install Conduit
following one of the different options provided
in [our installation page](/docs/installing-and-running).

:::note
The Conduit binary contains both, the Conduit service and the Conduit CLI, with
which you can interact with Conduit.
:::

## Initialize Conduit 

First, let's create a directory where we will build our first pipeline:

```shell
$ mkdir ~/conduit-playground/ && cd ~/conduit-playground/
```

Now, let's initialize the "working environment" in this directory:

```shell
$ conduit init

Created directory: processors
Created directory: connectors
Created directory: pipelines
Configuration file written to conduit.yaml

Conduit has been initialized!

To quickly create an example pipeline, run 'conduit pipelines init'.
To see how you can customize your first pipeline, run 'conduit pipelines init --help'.
```

`conduit init` creates the directories where you can put your pipeline
configuration files, connector binaries, and processor binaries. There's also a
`conduit.yaml` that contains all the configuration parameters Conduit supports.

In this guide, we'll only use the `pipelines` directory, since we won't need to
install any additional connector nor to change Conduit's default configuration.

## Build a pipeline

Next, we can use the Conduit CLI to build the example pipeline:

```shell
$ conduit pipelines init
```

If the `pipelines` directory, you'll notice a new file,
`pipeline-generator-to-log.yaml` that contains our pipeline's configuration:

```yaml
version: "2.2"
pipelines:
  - id: example-pipeline
    status: running
    name: "generator-to-log"
    connectors:
      - id: example-source
        type: source
        plugin: "generator"
        settings:
          # Generate field 'id' that's of the int type
          # Type: string
          # Optional
          format.options.id: 'int'
          # Generate field 'name' that's of the string type
          # Type: string
          # Optional
          format.options.name: 'string'
          # The format of the generated payload data (raw, structured, file).
          # Type: string
          # Optional
          format.type: 'structured'
          # The maximum rate in records per second, at which records are
          # generated (0 means no rate limit).
          # Type: float
          # Optional
          rate: '1'
      - id: example-destination
        type: destination
        plugin: "log"
```

The configuration above tells us some basic information about the pipeline (ID
and name) and that we want Conduit to start the pipeline automatically. We also
see a source connector, that uses the `generator` plugin, which is a built-in
plugin. The connector settings translate into: generate structured data, 1
record per second. Each generated record should contain an `id` field (type:
integer) and a `name` field (type: string).

Then we see that we have a destination connector where the data will be written
to. It uses the `log` plugin, which is a built-in plugin that logs all the
incoming data. No settings are used here because we're fine with the default
settings (data will be logged with the `INFO` level).
 
## Run Conduit

With the pipeline configuration being ready, we can run Conduit:

```shell
$ conduit --pipelines.path pipelines/
```

Conduit is now running the pipeline. Every second, you should see a line like
this in the logs:

```shell
2024-10-30T13:31:08+00:00 INF component=plugin connector_id=example-pipeline:example-destination plugin_name=log plugin_type=destination record={"key":"c3RhbGxib2FyZA==","metadata":{"conduit.source.connector.id":"example-pipeline:example-source","opencdc.createdAt":"1730291468447408842","opencdc.payload.schema.subject":"example-pipeline:example-source:payload","opencdc.payload.schema.version":"1"},"operation":"create","payload":{"after":{"id":3312758023475813349,"name":"representativity"},"before":null},"position":"MQ=="}
```

Here's just the generated record:

```json
{
    "key": "c3RhbGxib2FyZA==",
    "metadata":
    {
        "conduit.source.connector.id": "example-pipeline:example-source",
        "opencdc.createdAt": "1730291468447408842",
        "opencdc.payload.schema.subject": "example-pipeline:example-source:payload",
        "opencdc.payload.schema.version": "1"
    },
    "operation": "create",
    "payload":
    {
        "after":
        {
            "id": 3312758023475813349,
            "name": "representativity"
        },
        "before": null
    },
    "position": "MQ=="
}
```

The JSON object you see is the [OpenCDC record](/docs/using/opencdc-record) that
holds the data being streamed as well as other data and metadata. In the
`.payload.after` field you will see the user data that was generated by the
`generator` connector:

```json
{
    "id": 3312758023475813349,
    "name": "representativity"
}
```

The pipeline will keep streaming the data from the generator source connector to
the logging destination connector as long as Conduit is running.

## What's next?

Now that you've got the basics of running Conduit and creating a pipeline
covered, here are a few places to dive in deeper:
- [Connectors](/docs/using/connectors/getting-started)
- [Pipelines](/docs/using/pipelines/configuration-file)
- [Processors](/docs/using/processors/getting-started)

Or, if you want to experiment a bit more, check out the examples in
our [GitHub repository](https://github.com/ConduitIO/conduit/tree/main/examples).

<!-- TODO add scarf pixel -->
